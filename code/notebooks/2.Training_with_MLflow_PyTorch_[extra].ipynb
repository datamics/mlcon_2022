{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b55c51c6",
   "metadata": {},
   "source": [
    "<a href=\"https://akademie.datamics.com/kursliste/\">![title](../screenshots/bg_datamics_top.png)</a>\n",
    "\n",
    "<center><em>Â© Datamics</em></center><br><center><em>Check out our courses on <a href='https://akademie.datamics.com/kursliste/'>www.akademie.datamics.com</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbf1dc9",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb18d6",
   "metadata": {},
   "source": [
    "#### Install Pytorch by using pip command from \n",
    "<a href=\"https://pytorch.org/get-started/locally/\"> Pytorch official website</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7099739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dc1612",
   "metadata": {},
   "source": [
    "### Create and run mlflow server\n",
    "\n",
    "It connects the tracking URI, artifact and backend store to the non default locations\n",
    "\n",
    "`mlflow server --default-artifact-root /Users/saumyagoyal/JupyterNotebook/Datamics/MLCon_Berlin/local_artifact_store  --backend-store-uri sqlite:////Users/saumyagoyal/JupyterNotebook/Datamics/MLCon_Berlin/sqlite_backend_store/backend_store.db --host 127.0.0.1 --port 5500 >> mlflow_server_log.txt`\n",
    "\n",
    "<font color=#FF0000>**Note:** You can create mlflow server to run on a remote machine using the above command and connecting the backend (Example: AWS RDS instance) and artifact store(example: AWS S3 bucket) accordingly.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e03752",
   "metadata": {},
   "source": [
    "## Sample Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce1ea53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 332.771484375\n",
      "Loss: 233.3954315185547\n",
      "Loss: 164.6534881591797\n",
      "Loss: 117.0536880493164\n",
      "Loss: 84.06103515625\n",
      "Loss: 61.17106628417969\n",
      "Loss: 45.275299072265625\n",
      "Loss: 34.22660827636719\n",
      "Loss: 26.540191650390625\n",
      "Loss: 21.188249588012695\n",
      "Loss: 17.458749771118164\n",
      "Loss: 14.857793807983398\n",
      "Loss: 13.042466163635254\n",
      "Loss: 11.774591445922852\n",
      "Loss: 10.888429641723633\n",
      "Loss: 10.268638610839844\n",
      "Loss: 9.834870338439941\n",
      "Loss: 9.531110763549805\n",
      "Loss: 9.318270683288574\n",
      "Loss: 9.169050216674805\n",
      "checking if the experiment Experiment-9 already exists or not\n",
      "created a new experiment with experiment name Experiment-9\n",
      "\n",
      "\n",
      "Tracking URI: sqlite:////Users/saumyagoyal/JupyterNotebook/Datamics/MLCon_Berlin/sqlite_backend_store/backend_store.db\n",
      "Artifact Location: /Users/saumyagoyal/JupyterNotebook/Datamics/MLCon_Berlin/local_artifact_store/0ffa690f491f438786ac15c15b758ddf/artifacts\n",
      "--- Model logged successfully ---\n"
     ]
    }
   ],
   "source": [
    "#### new Pytorch model training with MLFlow #### \n",
    "\n",
    "import torch\n",
    "import math\n",
    "import mlflow\n",
    "\n",
    "# Create Tensors to hold input and outputs.\n",
    "x = torch.linspace(-math.pi, math.pi, 2000)\n",
    "y = torch.sin(x)\n",
    "\n",
    "# For this example, the output y is a linear function of (x, x^2, x^3), so\n",
    "# we can consider it as a linear layer neural network. Let's prepare the\n",
    "# tensor (x, x^2, x^3).\n",
    "p = torch.tensor([1, 2, 3])\n",
    "xx = x.unsqueeze(-1).pow(p)\n",
    "\n",
    "# In the above code, x.unsqueeze(-1) has shape (2000, 1), and p has shape\n",
    "# (3,), for this case, broadcasting semantics will apply to obtain a tensor\n",
    "# of shape (2000, 3)\n",
    "\n",
    "# Use the nn package to define our model as a sequence of layers. nn.Sequential\n",
    "# is a Module which contains other Modules, and applies them in sequence to\n",
    "# produce its output. The Linear Module computes output from input using a\n",
    "# linear function, and holds internal Tensors for its weight and bias.\n",
    "# The Flatten layer flatens the output of the linear layer to a 1D tensor,\n",
    "# to match the shape of `y`.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3, 1),\n",
    "    torch.nn.Flatten(0, 1)\n",
    ")\n",
    "\n",
    "# The nn package also contains definitions of popular loss functions; in this\n",
    "# case we will use Mean Squared Error (MSE) as our loss function.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "\n",
    "### Train the model ###\n",
    "\n",
    "learning_rate = 0.1e-5\n",
    "for t in range(2000):\n",
    "\n",
    "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
    "    # override the __call__ operator so you can call them like functions. When\n",
    "    # doing so you pass a Tensor of input data to the Module and it produces\n",
    "    # a Tensor of output data.\n",
    "    y_pred = model(xx)\n",
    "\n",
    "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
    "    # values of y, and the loss function returns a Tensor containing the\n",
    "    # loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(\"Loss:\", loss.item())\n",
    "\n",
    "    # Zero the gradients before running the backward pass.\n",
    "    model.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "    # parameters of the model. Internally, the parameters of each Module are stored\n",
    "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
    "    # all learnable parameters in the model.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
    "    # we can access its gradients like we did before.\n",
    "    with torch.no_grad():\n",
    "        for param in model.parameters():\n",
    "            param -= learning_rate * param.grad\n",
    "\n",
    "\n",
    "#######################################################\n",
    "################### MLflow code #######################\n",
    "#######################################################\n",
    "\n",
    "# setting the experiment details\n",
    "experiment_name = \"Experiment-9\"\n",
    "current_run_name = \"new Backend store\"\n",
    "artifact_location = \"/Users/saumyagoyal/JupyterNotebook/Datamics/MLCon_Berlin/local_artifact_store\"\n",
    "db_path = \"/Users/saumyagoyal/JupyterNotebook/Datamics/MLCon_Berlin/sqlite_backend_store/backend_store.db\"\n",
    "db_uri = \"sqlite:///\"+db_path\n",
    "\n",
    "# Set registry and tracking URI\n",
    "mlflow.set_registry_uri(db_uri)\n",
    "mlflow.set_tracking_uri(db_uri)\n",
    "\n",
    "# adding tags for each run\n",
    "tags = {\"Demo\": \"True\",\n",
    "        \"created-by\": \"dev team ID\"}\n",
    "\n",
    "# Creating new experiment  with artifact location only if the experiment doesn't exist\n",
    "print(f'checking if the experiment {experiment_name} already exists or not')\n",
    "\n",
    "if mlflow.get_experiment_by_name(experiment_name) == None :\n",
    "    mlflow.create_experiment(experiment_name, artifact_location)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    print(f\"created a new experiment with experiment name {experiment_name}\")\n",
    "else:\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    print(f\"Experiment {experiment_name} already exists, logging a new run with {current_run_name}\")\n",
    "\n",
    "# logging the current run\n",
    "with mlflow.start_run(run_name = current_run_name):\n",
    "\n",
    "    mlflow.set_tags(tags)\n",
    "\n",
    "    # logging parameters - from the Pytorch code\n",
    "    mlflow.log_param(\"learning rate\",learning_rate)\n",
    "    mlflow.log_param(\"loss\", loss.item())\n",
    "\n",
    "    # logging the model itself\n",
    "    mlflow.pytorch.log_model(model, \"Pytorch model\")\n",
    "\n",
    "    # Get storage location\n",
    "    print(\"\\n\\nTracking URI: {}\".format(mlflow.get_tracking_uri()))\n",
    "    print(\"Artifact Location: {}\".format(mlflow.get_artifact_uri()))\n",
    "    print(\"--- Model logged successfully ---\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f350018",
   "metadata": {},
   "source": [
    "### Check the logs in a new tracking server \n",
    "- Go to <a href='http://127.0.0.1:5500'> http://127.0.0.1:5500 </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43009709",
   "metadata": {},
   "source": [
    "![title](../screenshots/Pytorch_dashboard.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76645132",
   "metadata": {},
   "source": [
    "![title](../screenshots/Pytorch_model_registration.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4442fe2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h3> END </h3>\n",
    "</div> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
